太好了！按你在 **plan.md** 里给出的 W1 目标（“环境 & 数据 & 阅读卡（最小闭环）”，并在这一周内打通 **Dense ResNet-18**、指标 **Acc/ECE/NLL**、日志与初版 README/文献笔记）——我把它拆成**可执行的一周工程清单 + 代码骨架 + 验收标准**，一上来就能跑通最小闭环。

---

# 本周（W1）目标与产出（最小闭环）

**目标**：完成训练/评测流水线最小闭环（Dense 模型、CIFAR 数据管线、Acc/ECE/NLL 与可靠性图、日志与 README），为后续 MoE 与 Bayes 路由做地基。

**本周必交产物**

1. `README.md` 初版；2) `metrics/ece.py` 与 `metrics/nll.py`；3) `utils/reliability.py` 可靠性图；4) `train_dense.py` 可运行脚本；5) `notes/related_work.md`（阅读卡 1 页）。

> 全局题目与评测导向（校准 ECE/NLL、OOD/稳健性未来周完成）与课程 Rubric 对齐，见 plan.md 的选题与评分映射。&#x20;

---

# 一周日程（建议执行顺序）

**D1：环境与仓库骨架**

* 建虚拟环境 & 安装依赖

  ```bash
  conda create -n bayes-moe python=3.10 -y
  conda activate bayes-moe
  pip install torch torchvision torchaudio  # 选择与你CUDA匹配的轮子
  pip install numpy scipy scikit-learn matplotlib pyyaml tqdm
  ```
* 建项目结构

  ```
  bayes-moe/
  ├─ configs/
  │  └─ cifar100_resnet18.yaml
  ├─ data/   # 自动下载到这里（torchvision）
  ├─ metrics/
  │  ├─ ece.py
  │  └─ nll.py
  ├─ utils/
  │  └─ reliability.py
  ├─ train_dense.py
  ├─ README.md
  └─ notes/
     └─ related_work.md
  ```

**D2：数据管线（CIFAR-10/100、SVHN 占位）**

* 用 `torchvision.datasets` 打通 CIFAR-100 的 `train/val`，统一 Normalize（官方 mean/std）与基本增强（RandomCrop 32、Flip）。
* 先把 SVHN（未来做 OOD）加入 `datasets/__init__.py` 占位或在 `train_dense.py` 中留开关。

**D3：Dense ResNet-18 训练脚本**

* 采用 `torchvision.models.resnet18(num_classes=100)`，优化器 `SGD(lr=0.1, momentum=0.9, weight_decay=5e-4)`，`CosineAnnealingLR` 或 `MultiStepLR`。
* 先跑 **10\~20 epochs** 的“小训练”，记录 **top-1 Acc、NLL**；保存 `runs/cifar100-resnet18/*.csv` 日志与 `ckpt.pt`。

**D4：指标实现（ECE/NLL）与可靠性图**

* 在 `metrics/ece.py` 实现 **Expected Calibration Error**（默认 15 bins）；在 `metrics/nll.py` 直接用 CE 的平均作为 NLL。
* 在 `utils/reliability.py` 生成 **Reliability Diagram**（预测置信度分箱 vs 命中率），保存 `png/pdf`。

**D5：日志与可复现实验**

* 统一 `argparse`/`yaml` 读取配置；将 `seed`、`batch_size`、`lr`、`scheduler` 等写入 `configs/cifar100_resnet18.yaml`。
* 训练结束自动：打印/保存 `Acc/ECE/NLL`、导出 `reliability.png`。

**D6：阅读卡（1 页）**

* 选 3–4 篇：Switch/Expert-Choice MoE、Gumbel-Top-k、MC-Dropout（为后续 Bayes 路由做铺垫）。每篇 5 点卡片：问题、方法、核心公式/图、与我们差距、可复现实验要点。

**D7：验收与扫尾**

* 按下述“**验收标准**”逐项勾掉；在 `README.md` 写上 **运行命令、日志示例、指标与图**；`notes/related_work.md` 放入阅读卡要点。

---

# 代码骨架（可直接拷贝落地）

## 1) `metrics/ece.py`

```python
import torch

@torch.no_grad()
def expected_calibration_error(logits: torch.Tensor,
                               targets: torch.Tensor,
                               n_bins: int = 15):
    """
    logits: [N, C], raw scores
    targets: [N], long
    return: ece (float), bin_stats dict
    """
    probs = torch.softmax(logits, dim=1)
    confs, preds = probs.max(dim=1)
    targets = targets.to(preds.device)

    bin_boundaries = torch.linspace(0, 1, steps=n_bins + 1, device=confs.device)
    ece = torch.tensor(0., device=confs.device)
    bin_acc, bin_conf, bin_count = [], [], []

    N = confs.numel()
    for i in range(n_bins):
        lo, hi = bin_boundaries[i], bin_boundaries[i+1]
        in_bin = (confs > lo) & (confs <= hi) if i > 0 else (confs >= lo) & (confs <= hi)
        count = in_bin.sum().item()
        if count > 0:
            acc = (preds[in_bin] == targets[in_bin]).float().mean()
            conf = confs[in_bin].mean()
            gap = (conf - acc).abs()
            ece += gap * (count / N)
            bin_acc.append(acc.item()); bin_conf.append(conf.item()); bin_count.append(count)
        else:
            bin_acc.append(0.0); bin_conf.append(0.0); bin_count.append(0)
    return ece.item(), {"acc": bin_acc, "conf": bin_conf, "count": bin_count}
```

## 2) `metrics/nll.py`

```python
import torch
import torch.nn.functional as F

@torch.no_grad()
def negative_log_likelihood(logits: torch.Tensor, targets: torch.Tensor) -> float:
    return F.cross_entropy(logits, targets, reduction="mean").item()
```

## 3) `utils/reliability.py`

```python
import matplotlib.pyplot as plt

def plot_reliability(bin_stats, save_path: str):
    acc = bin_stats["acc"]; conf = bin_stats["conf"]
    bins = len(acc)
    xs = [(i+0.5)/bins for i in range(bins)]
    plt.figure()
    plt.plot([0,1],[0,1], linestyle="--")
    plt.bar(xs, acc, width=1.0/bins, edgecolor="black", alpha=0.6, label="Accuracy")
    plt.bar(xs, conf, width=1.0/bins, edgecolor="black", fill=False, label="Confidence")
    plt.xlabel("Confidence"); plt.ylabel("Accuracy / Confidence"); plt.legend()
    plt.tight_layout(); plt.savefig(save_path); plt.close()
```

## 4) `configs/cifar100_resnet18.yaml`

```yaml
dataset: cifar100
data_root: ./data
epochs: 20
batch_size: 128
num_workers: 4
model: resnet18
optimizer:
  name: sgd
  lr: 0.1
  momentum: 0.9
  weight_decay: 0.0005
scheduler:
  name: cosine
seed: 42
log_dir: ./runs/cifar100-resnet18
save_ckpt: true
```

## 5) `train_dense.py`（精简可跑）

```python
import os, argparse, yaml, random, numpy as np, torch
import torch.nn as nn, torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms, models
from metrics.ece import expected_calibration_error
from metrics.nll import negative_log_likelihood
from utils.reliability import plot_reliability

def set_seed(s):
    random.seed(s); np.random.seed(s); torch.manual_seed(s); torch.cuda.manual_seed_all(s)

def get_loaders(name, root, bs, nw):
    if name.lower() == "cifar100":
        mean, std = (0.5071,0.4867,0.4408), (0.2675,0.2565,0.2761)
        T_train = transforms.Compose([
            transforms.RandomCrop(32, padding=4),
            transforms.RandomHorizontalFlip(),
            transforms.ToTensor(), transforms.Normalize(mean, std)])
        T_test  = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean, std)])
        train = datasets.CIFAR100(root=root, train=True, download=True, transform=T_train)
        test  = datasets.CIFAR100(root=root, train=False, download=True, transform=T_test)
        return DataLoader(train, bs, shuffle=True, num_workers=nw, pin_memory=True), \
               DataLoader(test,  bs, shuffle=False, num_workers=nw, pin_memory=True)
    raise ValueError(f"Unknown dataset {name}")

def evaluate(net, loader, device):
    net.eval(); total, correct = 0, 0
    all_logits, all_targets = [], []
    with torch.no_grad():
        for x,y in loader:
            x,y = x.to(device), y.to(device)
            logits = net(x)
            all_logits.append(logits.cpu()); all_targets.append(y.cpu())
            pred = logits.argmax(1); total += y.size(0); correct += (pred==y).sum().item()
    logits = torch.cat(all_logits); targets = torch.cat(all_targets)
    acc = correct/total
    ece, bin_stats = expected_calibration_error(logits, targets, n_bins=15)
    nll = negative_log_likelihood(logits, targets)
    return acc, ece, nll, bin_stats

def main(cfg):
    set_seed(cfg.get("seed", 0))
    device = "cuda" if torch.cuda.is_available() else "cpu"
    os.makedirs(cfg["log_dir"], exist_ok=True)

    train_loader, test_loader = get_loaders(cfg["dataset"], cfg["data_root"],
                                            cfg["batch_size"], cfg["num_workers"])
    net = models.resnet18(weights=None, num_classes=100).to(device)
    criterion = nn.CrossEntropyLoss()
    opt = optim.SGD(net.parameters(), lr=cfg["optimizer"]["lr"],
                    momentum=cfg["optimizer"]["momentum"],
                    weight_decay=cfg["optimizer"]["weight_decay"])
    if cfg["scheduler"]["name"] == "cosine":
        sch = optim.lr_scheduler.CosineAnnealingLR(opt, T_max=cfg["epochs"])
    else:
        sch = None

    for epoch in range(1, cfg["epochs"]+1):
        net.train()
        for x,y in train_loader:
            x,y = x.to(device), y.to(device)
            opt.zero_grad()
            loss = criterion(net(x), y)
            loss.backward(); opt.step()
        if sch: sch.step()

    acc, ece, nll, bin_stats = evaluate(net, test_loader, device)
    plot_reliability(bin_stats, os.path.join(cfg["log_dir"], "reliability.png"))
    with open(os.path.join(cfg["log_dir"], "metrics.txt"), "w") as f:
        f.write(f"acc={acc:.4f}, ece={ece:.4f}, nll={nll:.4f}\n")
    if cfg.get("save_ckpt", True):
        torch.save(net.state_dict(), os.path.join(cfg["log_dir"], "ckpt.pt"))
    print(f"[TEST] acc={acc:.4f} ece={ece:.4f} nll={nll:.4f}")

if __name__ == "__main__":
    ap = argparse.ArgumentParser()
    ap.add_argument("--cfg", type=str, default="configs/cifar100_resnet18.yaml")
    args = ap.parse_args()
    with open(args.cfg, "r") as f: cfg = yaml.safe_load(f)
    main(cfg)
```

**运行示例**

```bash
python train_dense.py --cfg configs/cifar100_resnet18.yaml
# 结束后在 runs/cifar100-resnet18/ 下应看到:
#  - metrics.txt（含 acc/ece/nll）
#  - reliability.png
#  - ckpt.pt
```

---

# 验收标准（本周结束前自检清单）

* [ ] **能完整跑通**：`python train_dense.py` 在 CIFAR-100 上完成 10–20 epoch 训练并输出 `acc/ece/nll` 与 `reliability.png`。
* [ ] **指标正确**：`ece.py`/`nll.py` 单测通过（对极端情形：全对=ECE≈0，全错=ECE≈高，NLL 显著变大）。
* [ ] **日志可复现**：`configs/*.yaml` 能复跑相同结果±小抖动；`seed`/版本记录在 README。
* [ ] **README**：含环境、数据、训练命令、结果截图、后续 MoE 展望链接到 plan.md 对应周。
* [ ] **阅读卡**：`notes/related_work.md`（1 页，4 篇文献×5 点要素），为 W2/W3 的 MoE/MC-Dropout 做准备。

---

# 与 plan.md 的对齐说明

* **W1 范围**严格对应 “环境、数据、Dense 训练、Acc/ECE/NLL、README/文献笔记”，为后续 MoE/Bayes 路由与评测框架打地基。
* 整体研究题目与评测切面（校准/ECE、NLL、OOD、稳健性、计算开销）保持一致，为后续周逐步补齐。
* 周度产出与课程 Rubric（Contribution/Clarity/Depth/Literature/Formatting）映射持续积累。

---

如果你愿意，我还可以把这些文件打成一个**最小模板包**（同样目录/文件名），你直接 `git init` 后开工即可。


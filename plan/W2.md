好的！我刚把你的 GitHub 仓库重新过了一遍，并把第一周（W1）的结果梳理成一份「完成度小结 + 第二周（W2）详细行动清单」。下面是可直接对照执行的版本。

# W1 结果小结（本周验收）

**仓库结构**

* 顶层可见 `bayes-moe/`（代码目录）、`plan/`（计划/文档目录）、`README.md`（项目说明）。这与我们既定“W1 建好最小闭环骨架”的目标一致，说明仓库结构已经成型，可继续往 MoE 基线扩展。([GitHub][1])
* 语言统计显示以 **Python** 为主，符合项目技术栈预期。([GitHub][1])

**计划文档**

* 仓库中存在 `plan/` 目录（周计划与交付物的承载位置），便于按周验收与回溯。([GitHub][2])

> 说明：GitHub 的目录页在我这边偶尔出现加载失败（“Uh oh! There was an error while loading.”），因此我只能**确证顶层结构与目录存在**，对更深层文件（具体脚本/日志/图片）的网页端逐文件核验受限。如果你已经把训练脚本、指标实现、可靠性图、日志等放入 `bayes-moe/` 下的子目录，我建议把关键路径写进 README 的“复现实验”段落，方便任何人一条命令复现并定位产物（下面 W2 计划里我给出模板）。

**与 W1 目标的对齐度（结论：基本达标）**

* ✅ 仓库骨架与顶层文档到位（`bayes-moe/`、`plan/`、`README.md`）
* ✅ 计划承载位（`plan/`）存在，满足“周验收记录/目标对齐”的需要
* ⭕ 建议补充项：

  1. 在 `README.md` 增加**一键复现命令**与**产物路径**（如 `results/metrics.csv`、`plots/reliability.png`）。
  2. 在根目录提供 `requirements.txt`（或 `environment.yml`），固定 `python>=3.9`、`torch/torchvision/numpy/matplotlib` 等版本。
  3. 若你已完成 **Dense Baseline（ResNet-18 on CIFAR-10/100）** 的跑通，请把**日志与可靠性图**放到 `runs/<exp-name>/` 下，并在 README 放 1 张缩略图与指标摘要（Acc / NLL / ECE）。
  4. 指标实现（如 ECE / NLL）建议配 **最小单测**（`tests/test_metrics.py`）：构造几组可控 logits/labels，断言边界性质（完美校准 ECE≈0、极端错配时 ECE 较大等）。

---

# W2 详细计划（MoE 基线周）

**W2 目标（可验收）**
在现有骨架上，完成**标准稀疏 MoE 基线**并给出与 Dense 的首轮对照：

* 实现 **MoE-FFN/MLP**（4–8 专家；top-1→top-2 路由）、**负载均衡正则**、**token dispatch/combine**；
* 在 CIFAR-100（或当前数据集）上训练得到**对照表**（Accuracy / NLL / ECE + Params / FLOPs）；
* 可视化 **专家负载直方图** 与 **token-per-expert 热力图**；
* 给出复现命令、日志与图表路径；通过 `RESULTS.md` 汇总。

---

## 一、代码落地（目录与签名）

```text
bayes-moe/
├─ models/
│  ├─ backbones/
│  │  └─ resnet18.py
│  ├─ moe/
│  │  ├─ block.py          # MoEBlock(FFN替换件)
│  │  ├─ gate.py           # TopKGate / NoisyTopKGate
│  │  ├─ dispatcher.py     # token -> experts (indices, combine weights)
│  │  └─ balance_loss.py   # 负载均衡正则（aux loss）
│  └─ layers/
│     └─ mlp.py            # Dense-MLP（作对照）
├─ train/
│  ├─ train_dense.py
│  └─ train_moe.py
├─ metrics/
│  ├─ ece.py
│  ├─ nll.py
│  └─ reliability.py
├─ utils/
│  ├─ flops.py             # 估计Params/FLOPs（或用thop）
│  └─ seed.py
├─ configs/
│  ├─ cifar100_resnet18.yaml
│  └─ cifar100_resnet18_moe.yaml
├─ scripts/
│  └─ eval_cifar_c.py      # （可在W3再完善）
└─ tests/
   ├─ test_gate.py         # 路由形状/置换/梯度流
   └─ test_metrics.py
```

**关键类/函数（建议签名）**

* `TopKGate(nn.Module)`

  * `forward(x) -> (dispatch_idx, combine_weights, load_bal_stats)`
  * 参数：`num_experts, k, noisy=False, temperature=1.0`
* `MoEBlock(nn.Module)`（替换 Transformer-FFN/Conv-MLP 的位置）

  * `forward(x) -> y`，内部：`gate(x) -> dispatch -> experts -> combine`
  * 支持 `capacity_factor` 与 `drop_tokens=False/True`（先设 False 保守）
* `balance_loss(load_bal_stats, lb_coef)`

  * Shazeer 风格：鼓励各专家接收样本数量均衡（均值/方差正则化）

---

## 二、训练与评测（跑通即收敛）

**推荐配置（首轮）**

* 数据：CIFAR-100（若当前只有 CIFAR-10，先在 CIFAR-10 跑通）
* 模型：ResNet-18（Dense） vs. ResNet-18+MoE-MLP（`num_experts=4`，`top_k=1`）
* 优化：SGD+Momentum 0.9，WD=5e-4，Cosine LR（基础 LR 0.1，Warmup 5 epochs）
* 训练轮次：与 Dense 对齐；`lb_coef` 从 **0.01** 起，观察专家塌缩/负载曲线再调
* 日志：`runs/<dataset>/<model>-<stamp>/metrics.csv`、`events.out.tfevents*`
* 产物：`checkpoints/last.pt`、`plots/reliability.png`、`plots/load_hist.png`

**一键命令（README 建议示例）**

```bash
# Dense
python -m bayes-moe.train.train_dense \
  --config bayes-moe/configs/cifar100_resnet18.yaml

# MoE
python -m bayes-moe.train.train_moe \
  --config bayes-moe/configs/cifar100_resnet18_moe.yaml \
  --num_experts 4 --topk 1 --lb_coef 0.01
```

**评测输出（本周需提交）**

1. **主表 v0.1**（CSV + README 表格）：

   * Dense vs MoE：Accuracy / NLL / ECE（bins=15 或 20）
   * Params / FLOPs（记录估计方式：thop 或自写 `utils/flops.py`）
2. **图表**：

   * 可靠性图（Dense 与 MoE 各 1 张）
   * 专家负载直方图（tokens per expert）
   * （可选）Gate 选择的混淆热力图（expert × class）
3. **训练日志**：`metrics.csv`（每 epoch：acc、nll、ece、aux\_loss、gate\_entropy、utilization 等）

---

## 三、验证与单测（避免“跑通但不稳”）

* `tests/test_gate.py`：

  * 随机张量输入，断言：`dispatch_idx` 形状正确、`combine_weights` 对选中专家归一化、反向传播可达专家参数。
* `tests/test_metrics.py`：

  * 构造完美校准/极端过置信两组 logits，断言 ECE 单调、NLL 合理。
* 训练期 **诊断曲线**：

  * `utilization`（每专家接收样本数/比例）应在若干 epoch 内趋于均衡；如塌缩，调大 `lb_coef` 或短暂启用 `noisy gate`。

---

## 四、交付物清单（W2 周末前完成）

* [ ] `models/moe/{block.py,gate.py,dispatcher.py,balance_loss.py}` 可运行
* [ ] `configs/cifar100_resnet18_moe.yaml`（包含 `num_experts, topk, lb_coef`）
* [ ] `train/train_moe.py`（日志、保存、图表导出与 Dense 对齐）
* [ ] `RESULTS.md`（主表 v0.1 + 两张关键图 + 训练命令）
* [ ] `README.md` 更新：复现步骤、示例命令、结果截图
* [ ] `tests/` 两个基础单测通过

---

## 五、风险与对策

* **专家塌缩/利用率失衡** → 提高 `lb_coef`；前 1–2 epoch 打开 `noisy gate`；限制 `capacity_factor` 避免少数专家超载。
* **ECE 无改善或变差** → 降温（`temperature<1`）或增加 `topk=2`；训练后对比**温度缩放**；用固定 bins（15/20）保持可比性。
* **FLOPs 失控** → 报告 **实际吞吐**（samples/s）和估计 FLOPs；MoE 只替换 MLP，不动 backbone。

---

## 六、建议在 Issues/Milestones 中落地

**里程碑：W2-MoE-Baseline**（含任务：实现、训练、评测、文档）

* Issue #1：实现 `TopKGate` 与 `MoEBlock`（带最小单测）
* Issue #2：`train_moe.py` 与 YAML 配置
* Issue #3：负载均衡正则与可视化（直方图/热力图）
* Issue #4：主表 v0.1 生成脚本（导出 CSV + README 表格片段）
* Issue #5：README/RESULTS.md 文档化与截图

---

如果你愿意，我也可以把 **`TopKGate`/`MoEBlock` 的最小骨架**和 **负载均衡正则**（Shazeer 风格）直接写成可拷贝的代码片段，按上面的目录对齐即可集成。当前这版总结与计划已与仓库结构核对过顶层项（`bayes-moe/`、`plan/`、`README.md`），细节文件因为 GitHub 页面偶发加载问题暂未逐项点开核验——如果你把核心脚本路径写进 README 的“复现实验”段落，后续任何人都能按一条命令复现并完成外部审查。 ([GitHub][1])

[1]: https://github.com/Pseudonymous-gdy/Deep-Learning-Project "GitHub - Pseudonymous-gdy/Deep-Learning-Project: A toy example of deep learning projects on model architecture."
[2]: https://github.com/Pseudonymous-gdy/Deep-Learning-Project/tree/main/plan "Deep-Learning-Project/plan at main · Pseudonymous-gdy/Deep-Learning-Project · GitHub"
